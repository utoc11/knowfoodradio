#!/usr/bin/env python3
"""
NotebookLMç”¨ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰æƒ…å ±ã‚’æŒ‡å®šã•ã‚ŒãŸã‚°ãƒ«ãƒ¼ãƒ—ã‚µã‚¤ã‚ºã§ã¾ã¨ã‚ã¦ã€NotebookLMã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã‚„ã™ã„å½¢å¼ã§å‡ºåŠ›ã—ã¾ã™ã€‚
"""

import os
import json
import shutil
from pathlib import Path
from typing import List, Dict
import argparse

class NotebookLMFileCreator:
    def __init__(self, base_dir: str = "/Users/yutokikuchi/dev/knowfoodradio", group_size: int = 10):
        self.base_dir = Path(base_dir)
        self.from_rss_dir = self.base_dir / "from-rss"
        self.output_dir = self.base_dir / "notebooklm"
        self.group_size = group_size
        
    def setup_output_directory(self):
        """å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆï¼ˆæ—¢å­˜ã®å ´åˆã¯å‰Šé™¤ã—ã¦å†ä½œæˆï¼‰"""
        if self.output_dir.exists():
            shutil.rmtree(self.output_dir)
        self.output_dir.mkdir(exist_ok=True)
        print(f"âœ… å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆã—ã¾ã—ãŸ: {self.output_dir}")
        
    def copy_overview_file(self):
        """KNOWãƒ•ãƒ¼ãƒ‰ãƒ©ã‚¸ã‚ªã¨ã¯.mdã‚’ã‚³ãƒ”ãƒ¼"""
        source = self.base_dir / "KNOWãƒ•ãƒ¼ãƒ‰ãƒ©ã‚¸ã‚ªã¨ã¯.md"
        dest = self.output_dir / "00_KNOWãƒ•ãƒ¼ãƒ‰ãƒ©ã‚¸ã‚ªã¨ã¯.md"
        
        if source.exists():
            shutil.copy2(source, dest)
            print(f"âœ… ç•ªçµ„æ¦‚è¦ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚³ãƒ”ãƒ¼ã—ã¾ã—ãŸ: {dest.name}")
        else:
            print(f"âš ï¸  ç•ªçµ„æ¦‚è¦ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {source}")
            
    def get_episode_directories(self) -> List[Path]:
        """from-rsså†…ã®ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å–å¾—"""
        if not self.from_rss_dir.exists():
            print(f"âŒ from-rssãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {self.from_rss_dir}")
            return []
            
        episodes = []
        for item in sorted(self.from_rss_dir.iterdir()):
            if item.is_dir() and not item.name.startswith('.'):
                episodes.append(item)
        
        print(f"ğŸ“ {len(episodes)}å€‹ã®ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ç™ºè¦‹")
        return episodes
        
    def read_episode_data(self, episode_dir: Path) -> Dict:
        """ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰å¿…è¦ãªæƒ…å ±ã‚’èª­ã¿è¾¼ã‚€"""
        data = {
            "title": episode_dir.name,
            "path": str(episode_dir),
            "content": {}
        }
        
        # èª­ã¿è¾¼ã‚€ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒªã‚¹ãƒˆï¼ˆå„ªå…ˆé †ä½é †ï¼‰
        files_to_read = [
            ("metadata.json", "metadata"),
            ("summary.md", "summary"),
            ("briefing.md", "briefing"),
            ("highlights.md", "highlights"),
            ("timeline.md", "timeline"),
            ("keywords.txt", "keywords"),
            ("quotes.txt", "quotes"),
            ("questions.txt", "questions")
        ]
        
        for filename, key in files_to_read:
            file_path = episode_dir / filename
            if file_path.exists():
                try:
                    if filename.endswith('.json'):
                        with open(file_path, 'r', encoding='utf-8') as f:
                            data["content"][key] = json.load(f)
                    else:
                        with open(file_path, 'r', encoding='utf-8') as f:
                            data["content"][key] = f.read()
                except Exception as e:
                    print(f"  âš ï¸  {filename}ã®èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
                    
        return data
        
    def format_episode_content(self, episode_data: Dict) -> str:
        """ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿ã‚„ã™ã„å½¢å¼ã«ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
        lines = []
        
        # ã‚¿ã‚¤ãƒˆãƒ«
        lines.append(f"# ğŸ™ï¸ {episode_data['title']}")
        lines.append("")
        
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
        if "metadata" in episode_data["content"]:
            meta = episode_data["content"]["metadata"]
            lines.append("## ğŸ“Š ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰æƒ…å ±")
            if "pub_date" in meta:
                lines.append(f"- **é…ä¿¡æ—¥**: {meta['pub_date']}")
            if "duration" in meta:
                lines.append(f"- **åéŒ²æ™‚é–“**: {meta['duration']}")
            if "episode_number" in meta and meta["episode_number"]:
                lines.append(f"- **ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ç•ªå·**: #{meta['episode_number']}")
            lines.append("")
            
        # ã‚µãƒãƒªãƒ¼
        if "summary" in episode_data["content"]:
            lines.append("## ğŸ“ è¦ç´„")
            lines.append(episode_data["content"]["summary"])
            lines.append("")
            
        # ãƒ–ãƒªãƒ¼ãƒ•ã‚£ãƒ³ã‚°
        if "briefing" in episode_data["content"]:
            lines.append("## ğŸ“‹ è©³ç´°ãƒ–ãƒªãƒ¼ãƒ•ã‚£ãƒ³ã‚°")
            lines.append(episode_data["content"]["briefing"])
            lines.append("")
            
        # ãƒã‚¤ãƒ©ã‚¤ãƒˆ
        if "highlights" in episode_data["content"]:
            lines.append("## âœ¨ ãƒã‚¤ãƒ©ã‚¤ãƒˆ")
            lines.append(episode_data["content"]["highlights"])
            lines.append("")
            
        # ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³
        if "timeline" in episode_data["content"]:
            lines.append("## â±ï¸ ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³")
            lines.append(episode_data["content"]["timeline"])
            lines.append("")
            
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
        if "keywords" in episode_data["content"]:
            lines.append("## ğŸ·ï¸ ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰")
            lines.append(episode_data["content"]["keywords"])
            lines.append("")
            
        # å¼•ç”¨
        if "quotes" in episode_data["content"]:
            lines.append("## ğŸ’¬ å°è±¡çš„ãªç™ºè¨€")
            lines.append(episode_data["content"]["quotes"])
            lines.append("")
            
        # è³ªå•
        if "questions" in episode_data["content"]:
            lines.append("## â“ æƒ³å®šè³ªå•")
            lines.append(episode_data["content"]["questions"])
            lines.append("")
            
            
        lines.append("---")
        lines.append("")
        
        return "\n".join(lines)
        
    def create_grouped_files(self, episodes: List[Path]):
        """ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã‚’ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã—ã¦ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ"""
        total_episodes = len(episodes)
        total_groups = (total_episodes + self.group_size - 1) // self.group_size
        
        print(f"\nğŸ“Š {total_episodes}ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã‚’{self.group_size}å€‹ãšã¤ã€è¨ˆ{total_groups}ãƒ•ã‚¡ã‚¤ãƒ«ã«åˆ†å‰²ã—ã¾ã™")
        
        for group_index in range(total_groups):
            start_idx = group_index * self.group_size
            end_idx = min(start_idx + self.group_size, total_episodes)
            group_episodes = episodes[start_idx:end_idx]
            
            # ãƒ•ã‚¡ã‚¤ãƒ«åã‚’æ±ºå®šï¼ˆ01_episodes_001-010.md ã®ã‚ˆã†ãªå½¢å¼ï¼‰
            start_num = start_idx + 1
            end_num = end_idx
            filename = f"{group_index + 1:02d}_episodes_{start_num:03d}-{end_num:03d}.md"
            output_path = self.output_dir / filename
            
            print(f"\nğŸ“ {filename}ã‚’ä½œæˆä¸­...")
            
            # ã‚°ãƒ«ãƒ¼ãƒ—å†…ã®ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿ã‚’åé›†
            content_lines = []
            content_lines.append(f"# KNOWãƒ•ãƒ¼ãƒ‰ãƒ©ã‚¸ã‚ª ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰é›† ({start_num}-{end_num})")
            content_lines.append("")
            content_lines.append(f"ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã«ã¯ã€KNOWãƒ•ãƒ¼ãƒ‰ãƒ©ã‚¸ã‚ªã®ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰{start_num}ã‹ã‚‰{end_num}ã¾ã§ã®æƒ…å ±ãŒã¾ã¨ã‚ã‚‰ã‚Œã¦ã„ã¾ã™ã€‚")
            content_lines.append("")
            content_lines.append("---")
            content_lines.append("")
            
            for i, episode_dir in enumerate(group_episodes):
                print(f"  - {episode_dir.name}ã‚’å‡¦ç†ä¸­...")
                episode_data = self.read_episode_data(episode_dir)
                formatted_content = self.format_episode_content(episode_data)
                content_lines.append(formatted_content)
                
            # ãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãå‡ºã—
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write("\n".join(content_lines))
                
            print(f"  âœ… {filename}ã‚’ä½œæˆã—ã¾ã—ãŸ ({len(group_episodes)}ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰)")
            
    def create_index_file(self, episodes: List[Path]):
        """å…¨ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ"""
        index_path = self.output_dir / "00_INDEX.md"
        
        lines = []
        lines.append("# KNOWãƒ•ãƒ¼ãƒ‰ãƒ©ã‚¸ã‚ª ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹")
        lines.append("")
        lines.append(f"å…¨{len(episodes)}ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã®ä¸€è¦§ã§ã™ã€‚")
        lines.append("")
        
        for i, episode_dir in enumerate(episodes, 1):
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚“ã§æ—¥ä»˜ã‚’å–å¾—
            metadata_path = episode_dir / "metadata.json"
            pub_date = ""
            if metadata_path.exists():
                try:
                    with open(metadata_path, 'r', encoding='utf-8') as f:
                        metadata = json.load(f)
                        pub_date = metadata.get("pub_date", "")
                except:
                    pass
                    
            lines.append(f"{i:03d}. {episode_dir.name} ({pub_date})")
            
        with open(index_path, 'w', encoding='utf-8') as f:
            f.write("\n".join(lines))
            
        print(f"âœ… ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã¾ã—ãŸ: {index_path.name}")
        
    def run(self):
        """ãƒ¡ã‚¤ãƒ³å‡¦ç†ã‚’å®Ÿè¡Œ"""
        print("ğŸš€ NotebookLMç”¨ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆã‚’é–‹å§‹ã—ã¾ã™")
        print(f"   ã‚°ãƒ«ãƒ¼ãƒ—ã‚µã‚¤ã‚º: {self.group_size}ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰/ãƒ•ã‚¡ã‚¤ãƒ«")
        
        # 1. å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
        self.setup_output_directory()
        
        # 2. ç•ªçµ„æ¦‚è¦ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚³ãƒ”ãƒ¼
        self.copy_overview_file()
        
        # 3. ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å–å¾—
        episodes = self.get_episode_directories()
        if not episodes:
            print("âŒ ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            return
            
        # 4. ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
        self.create_index_file(episodes)
        
        # 5. ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
        self.create_grouped_files(episodes)
        
        # å®Œäº†ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        print("\nâœ¨ å®Œäº†ã—ã¾ã—ãŸï¼")
        print(f"ğŸ“ ä½œæˆã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã¯ä»¥ä¸‹ã«ã‚ã‚Šã¾ã™:")
        print(f"   {self.output_dir}")
        print("\nğŸ’¡ ä½¿ã„æ–¹:")
        print("   1. Finderã§ä¸Šè¨˜ã®ãƒ•ã‚©ãƒ«ãƒ€ã‚’é–‹ã")
        print("   2. ã™ã¹ã¦ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠï¼ˆCmd+Aï¼‰")
        print("   3. NotebookLMã«ãƒ‰ãƒ©ãƒƒã‚°&ãƒ‰ãƒ­ãƒƒãƒ—")


def main():
    parser = argparse.ArgumentParser(
        description="NotebookLMç”¨ã«KNOWãƒ•ãƒ¼ãƒ‰ãƒ©ã‚¸ã‚ªã®ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰æƒ…å ±ã‚’ã¾ã¨ã‚ãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã¾ã™"
    )
    parser.add_argument(
        "-g", "--group-size",
        type=int,
        default=10,
        help="1ãƒ•ã‚¡ã‚¤ãƒ«ã«ã¾ã¨ã‚ã‚‹ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 10ï¼‰"
    )
    parser.add_argument(
        "-d", "--directory",
        type=str,
        default="/Users/yutokikuchi/dev/knowfoodradio",
        help="KNOWãƒ•ãƒ¼ãƒ‰ãƒ©ã‚¸ã‚ªã®ãƒ™ãƒ¼ã‚¹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª"
    )
    
    args = parser.parse_args()
    
    creator = NotebookLMFileCreator(
        base_dir=args.directory,
        group_size=args.group_size
    )
    creator.run()


if __name__ == "__main__":
    main()