# KNOWフードラジオ - 文字起こし管理システム

Podcast番組「KNOWフードラジオ」の文字起こしデータを管理し、番組運営に役立つ派生テキストを生成するためのシステムです。

## セットアップ

### 必要な環境
- Python 3.9以上
- pipenv

### インストール
```bash
# 依存関係のインストール
pipenv install

# 開発環境の場合
pipenv install --dev
```

## 使い方

### 文字起こしの取得

```bash
# 仮想環境を有効化
pipenv shell

# 最新エピソードを取得
python fetch_transcript.py

# または pipenv run を使用
pipenv run fetch

# 特定の年月のエピソードを取得
pipenv run python fetch_transcript.py --year-month 2024-01

# 期間を指定して取得
pipenv run python fetch_transcript.py --from 2024-01-01 --to 2024-03-31

# 全エピソードを取得
pipenv run fetch-all
```

### ディレクトリ構造

- `manual/` - 配信前の手動管理エピソード
- `from-rss/` - RSS経由で取得した配信済みエピソード
- `templates/` - 出力フォーマットの参考例

詳細は[PLANNING.md](PLANNING.md)を参照してください。

## 派生テキストの生成

文字起こしから以下のような派生テキストをLLMに依頼して生成できます：

### 基本的な派生テキスト
- 要約（summary.md）- 200-300文字の簡潔な要約
- ブリーフィング・ドキュメント（briefing.md）- 800-1200文字の詳細レポート
- ハイライト（highlights.md）- 30秒〜1分30秒の切り抜き候補
- 目次（timeline.md）- mm:ss形式のタイムスタンプ付き目次
- SNS投稿文（social/instagram.txt、social/x.txt）

### 追加の派生テキスト
- キーワード（keywords.txt）- SEO対策用
- 引用集（quotes.txt）- 印象的な発言
- 質問リスト（questions.txt）- 想定質問と企画案
- リスナー問いかけ（audience_engagement.txt）- SNS用の問いかけ
- 関連リンク（links.md）- 参考URL集

## 実際の使用例

### 配信済みエピソードの処理
```bash
# 1. 最新エピソードを取得
pipenv run fetch

# 2. LLMに派生テキスト作成を依頼
# 「from-rss/第30回_XXX/の文字起こしから派生テキストを作成してください」
# ※必ずCONTENT_GUIDELINES.mdに従うよう指示
```

### 配信前エピソードの準備
```bash
# manual/配下にtimeline-review.mdを配置後
# 「manual/#30.1-お便り回/のtimeline-review.mdから配信予告を作成してください」
```

## 重要なドキュメント

- [PLANNING.md](PLANNING.md) - ディレクトリ構造と運用フロー
- [CONTENT_GUIDELINES.md](CONTENT_GUIDELINES.md) - 派生テキストの品質基準
- [BEST_PRACTICES.md](BEST_PRACTICES.md) - トラブルシューティングとコツ

## NotebookLM連携

NotebookLM（Google製のAI対話ツール）と連携して、番組内容の深い分析や新しい視点での洞察を得ることができます。

### NotebookLM用ファイルの生成

```bash
# デフォルト設定（10エピソードごとにグループ化）
python create_notebooklm_files.py

# カスタム設定例
python create_notebooklm_files.py --group-size 20  # 20エピソードごと
```

### 生成されるファイル

`notebooklm/`ディレクトリに以下のファイルが生成されます：

- `00_KNOWフードラジオとは.md` - 番組概要
- `00_INDEX.md` - 全エピソードのインデックス
- `01_episodes_001-010.md` - エピソード1-10の統合ファイル
- `02_episodes_011-020.md` - エピソード11-20の統合ファイル
- ... （以降、指定したグループサイズごとに分割）

### NotebookLMへのアップロード方法

1. `python create_notebooklm_files.py`を実行
2. Finderで`notebooklm/`フォルダを開く
3. すべてのファイルを選択（Cmd+A）
4. NotebookLMにドラッグ&ドロップ

### 活用例

- エピソード間の関連性を発見
- 番組全体のテーマ分析
- ゲストごとの洞察の比較
- 時系列での話題の変遷分析

## 文字起こしの解析

### 「へぇ」リアクション解析

文字起こしファイルから「へぇ」「へー」「へえ」などのリアクションを抽出・集計できます。

**精度向上のポイント**:
- 1文字ごとのスペース（`へ え`）に対応
- 改行を含むパターン（`へ\nえ`）に対応
- 全角スペースに対応（`へ　え`）
- 複数文字の繰り返し（`へええ`、`へえー`）に対応
- スペースと改行の混在（`へ \n え`）に対応

```bash
# 全エピソードを解析（デフォルトで前後2ブロックのコンテキスト付き）
python analyze_hee.py --all

# 詳細情報（タイムスタンプと文脈）を表示
python analyze_hee.py --all --details

# 特定のエピソードのみ解析
python analyze_hee.py "#32.機能性表示食品は誰のため？開発者目線で見るトクホとの違い"

# JSON形式で結果を保存（自動的にMarkdownも生成される）
python analyze_hee.py --all --json hee_analysis_result.json
# → hee_analysis_result.json と hee_analysis_result.md が生成される

# Markdown形式のみで保存
python analyze_hee.py --all --markdown hee_analysis_result.md

# === コンテキスト（前後の文脈）のカスタマイズ ===

# コンテキストなし（「へぇ」の箇所のみ）
python analyze_hee.py --all --details --context 0

# 前後を広く取る（前後5ブロック）
python analyze_hee.py "#32.機能性表示食品は誰のため？開発者目線で見るトクホとの違い" --details --context 5

# === 並び順のカスタマイズ ===

# へぇ回数の多い順（デフォルト）
python analyze_hee.py --all --sort count-desc

# へぇ回数の少ない順
python analyze_hee.py --all --sort count-asc

# エピソード名順
python analyze_hee.py --all --sort name

# === 差分実行（新しいエピソードのみ処理） ===

# 初回: 全エピソードを解析してJSONに保存
python analyze_hee.py --all --json hee_analysis_result.json

# 2回目以降: 新しいエピソードのみを解析して既存結果に追加
python analyze_hee.py --all --json hee_analysis_result.json --incremental

# 差分実行の例（実際の出力）
# 差分実行モード: 既存結果を読み込んでいます (hee_analysis_result.json)...
#   → 146件の処理済みエピソードを検出
# 全エピソードを解析中...
#
# 差分実行完了:
#   - 新規解析: 3件
#   - スキップ: 146件
#   - 合計: 149件

# === 連番付きエピソードのみを対象 ===

# #数字で始まるエピソード（#1、#36など）のみを解析
python analyze_hee.py --all --numbered-only --json hee_analysis_numbered.json

# 連番付きのみ + へぇ回数の多い順
python analyze_hee.py --all --numbered-only --sort count-desc --json hee_analysis_numbered.json
```

**💡 重要**:
- デフォルトで**へぇ回数の多い順**に並びます
- デフォルトで前後2ブロック（約10-15秒の会話）のコンテキストが自動的に含まれます
- **差分実行（`--incremental`）を使うと、既に処理済みのエピソードをスキップして新しいエピソードのみを解析できます**
  - 毎週更新されるポッドキャストに最適
  - 処理時間を大幅に短縮
  - `--json`オプションと併用必須
- **連番フィルター（`--numbered-only`）を使うと、#数字で始まるエピソードのみを対象にできます**
  - お便り回やゲスト回など、連番外のエピソードを除外したい場合に便利
  - 例: `#1`、`#36`は対象、`#36.1-お便り回`は対象外

### 解析結果の例

```
================================================================================
「へぇ」リアクション解析結果
================================================================================

解析エピソード数: 146
「へぇ」を含むエピソード数: 91
「へぇ」総出現回数: 240

--------------------------------------------------------------------------------
エピソードごとの「へぇ」カウント（デフォルト：回数の多い順）
--------------------------------------------------------------------------------
[11回] 魚だけじゃない！体に良い油もテクノロジーで解決！？ #100 〜脂肪酸の科学⑤
[ 8回] 【AI×植物工場】100倍速で進化する『Oishii Farm』のイチゴがすごい！〜農食ザ・ワールドアメリカ篇 #47
[ 7回] #07.代替肉はホンモノになれるのか？肉欲を満たすフードテック！〜肉食の世界③
[ 7回] 梅のチカラは無限大！健康と美味しさのカギはクエン酸！？【梅酒①】 #68
  └ 00:10:19,400: とか甘くて飲めなくなったりもするし、へえっていうその嗜好性の部分も...
  ...
```

### JSON出力形式

`--json`オプションで出力されるJSON形式の構造:

```json
[
  {
    "episode_name": "#32.機能性表示食品は誰のため？開発者目線で見るトクホとの違い",
    "count": 1,
    "instances": [
      {
        "timestamp": "00:01:58,960 --> 00:02:00,960",
        "text": "へ え、 効 果。 感 じ て る ん だ。",
        "cleaned_text": "へえ、効果。感じてるんだ。",
        "context": "みたい。な、本当に手ずっと動かしてる時とか食べてんだけど、まあなんか確かに圧迫感が減る気がする。へえ、効果。感じてるんだ。そうそう。実績わかんないよね。これはあれかもしれないけどね。プラシーボ効果かもしれないけどね。"
      }
    ]
  },
  {
    "episode_name": "#01.熱中症対策の甘いジュース、それ本当に大丈夫？〜砂糖の世界①",
    "count": 4,
    "instances": [
      {
        "timestamp": "00:10:19,400 --> 00:10:23,920",
        "text": "と か 甘 く て 飲 め な く な っ た り も す る し、 へ え っ て い う そ の 嗜 好 性 の 部 分 も",
        "cleaned_text": "とか甘くて飲めなくなったりもするし、へえっていうその嗜好性の部分も",
        "context": "前後のテキストを含む長い文章..."
      }
      // ... 残りの3件
    ]
  }
  // ... 他のエピソード
]
```

**フィールド説明**:
- `episode_name`: エピソード名
- `count`: そのエピソードでの「へぇ」の出現回数
- `instances`: 「へぇ」が出現した箇所の詳細リスト
  - `timestamp`: SRTファイルのタイムスタンプ（開始 --> 終了）
  - `text`: 元のテキスト（スペース入り）
  - `cleaned_text`: スペースを除去したテキスト（読みやすい形式）
  - `context`: 前後のコンテキストを含むテキスト（`--context`オプション使用時のみ、デフォルトは前後2ブロック）

### Markdown出力形式

`--markdown`オプションまたは`--json`オプション使用時に自動生成されるMarkdown形式のサンプル:

```markdown
# 「へぇ」リアクション解析結果

## 📊 サマリ

- **解析エピソード数**: 1
- **「へぇ」を含むエピソード数**: 1
- **「へぇ」総出現回数**: 4

## 📝 エピソードごとの詳細

### #01.熱中症対策の甘いジュース、それ本当に大丈夫？〜砂糖の世界①

**出現回数**: 4回

#### 1. タイムスタンプ: `00:10:19,400`

> あ。これまでの夏さまあ、結構俺もね、畑に出てうん調査とかしてたからすごい汗かくわけうんで、やっぱりポカリとか甘くて飲めなくなったりもするし、へえっていうその嗜好性の部分もあるし。はい。あと普通にさ一時間に一本とか飲むわけよ？

#### 2. タイムスタンプ: `00:14:57,640`

> 甘く感じんだよね？なるほど。だからフルーツ冷やして甘くてうまい。ってことなんだよへえでちなみに加藤、葡萄糖なんだけど、葡萄糖はあのなんか最近集中力上がるやつみたいので。あ、ラムネ。あのラムネに入ってたりとかブドウ

---

## 📌 注意

このファイルは `analyze_hee.py` によって自動生成されました。
```

**特徴**:
- 絵文字付きの見出しで視認性向上
- エピソードごとにグループ化
- タイムスタンプとコンテキストを含む引用形式
- 人間が読みやすいフォーマット
- `--json`使用時は自動的に同名の`.md`ファイルも生成

### 活用方法

- **番組の盛り上がりポイントの特定**: 「へぇ」が多いエピソードは、驚きや発見が多い回
- **切り抜き候補の発見**: 「へぇ」の前後は視聴者の興味を引く内容
- **ゲストの反応分析**: ゲスト回での「へぇ」の多さで興味度を測定
- **コンテンツ改善**: 「へぇ」が少ないテーマは説明方法の見直しも検討
- **データ分析**: JSON形式で出力すれば、他のツールやスクリプトで更なる分析が可能

## 開発

```bash
# コードフォーマット
pipenv run format

# リンター実行
pipenv run lint

# 型チェック
pipenv run typecheck
```