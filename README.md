# KNOWフードラジオ - 文字起こし管理システム

Podcast番組「KNOWフードラジオ」の文字起こしデータを管理し、番組運営に役立つ派生テキストを生成するためのシステムです。

## セットアップ

### 必要な環境
- Python 3.9以上
- pipenv

### インストール
```bash
# 依存関係のインストール
pipenv install

# 開発環境の場合
pipenv install --dev
```

## 使い方

### 文字起こしの取得

```bash
# 仮想環境を有効化
pipenv shell

# 最新エピソードを取得
python fetch_transcript.py

# または pipenv run を使用
pipenv run fetch

# 特定の年月のエピソードを取得
pipenv run python fetch_transcript.py --year-month 2024-01

# 期間を指定して取得
pipenv run python fetch_transcript.py --from 2024-01-01 --to 2024-03-31

# 全エピソードを取得
pipenv run fetch-all
```

### ディレクトリ構造

- `manual/` - 配信前の手動管理エピソード
- `from-rss/` - RSS経由で取得した配信済みエピソード
- `templates/` - 出力フォーマットの参考例

詳細は[PLANNING.md](PLANNING.md)を参照してください。

## 派生テキストの生成

文字起こしから以下のような派生テキストをLLMに依頼して生成できます：

### 基本的な派生テキスト
- 要約（summary.md）- 200-300文字の簡潔な要約
- ブリーフィング・ドキュメント（briefing.md）- 800-1200文字の詳細レポート
- ハイライト（highlights.md）- 30秒〜1分30秒の切り抜き候補
- 目次（timeline.md）- mm:ss形式のタイムスタンプ付き目次
- SNS投稿文（social/instagram.txt、social/x.txt）

### 追加の派生テキスト
- キーワード（keywords.txt）- SEO対策用
- 引用集（quotes.txt）- 印象的な発言
- 質問リスト（questions.txt）- 想定質問と企画案
- リスナー問いかけ（audience_engagement.txt）- SNS用の問いかけ
- 関連リンク（links.md）- 参考URL集

## 実際の使用例

### 配信済みエピソードの処理
```bash
# 1. 最新エピソードを取得
pipenv run fetch

# 2. LLMに派生テキスト作成を依頼
# 「from-rss/第30回_XXX/の文字起こしから派生テキストを作成してください」
# ※必ずCONTENT_GUIDELINES.mdに従うよう指示
```

### 配信前エピソードの準備
```bash
# manual/配下にtimeline-review.mdを配置後
# 「manual/#30.1-お便り回/のtimeline-review.mdから配信予告を作成してください」
```

## 重要なドキュメント

- [PLANNING.md](PLANNING.md) - ディレクトリ構造と運用フロー
- [CONTENT_GUIDELINES.md](CONTENT_GUIDELINES.md) - 派生テキストの品質基準
- [BEST_PRACTICES.md](BEST_PRACTICES.md) - トラブルシューティングとコツ

## NotebookLM連携

NotebookLM（Google製のAI対話ツール）と連携して、番組内容の深い分析や新しい視点での洞察を得ることができます。

### NotebookLM用ファイルの生成

```bash
# デフォルト設定（10エピソードごとにグループ化）
python create_notebooklm_files.py

# カスタム設定例
python create_notebooklm_files.py --group-size 20  # 20エピソードごと
```

### 生成されるファイル

`notebooklm/`ディレクトリに以下のファイルが生成されます：

- `00_KNOWフードラジオとは.md` - 番組概要
- `00_INDEX.md` - 全エピソードのインデックス
- `01_episodes_001-010.md` - エピソード1-10の統合ファイル
- `02_episodes_011-020.md` - エピソード11-20の統合ファイル
- ... （以降、指定したグループサイズごとに分割）

### NotebookLMへのアップロード方法

1. `python create_notebooklm_files.py`を実行
2. Finderで`notebooklm/`フォルダを開く
3. すべてのファイルを選択（Cmd+A）
4. NotebookLMにドラッグ&ドロップ

### 活用例

- エピソード間の関連性を発見
- 番組全体のテーマ分析
- ゲストごとの洞察の比較
- 時系列での話題の変遷分析

## 文字起こしの解析

### 「へぇ」リアクション解析

文字起こしファイルから「へぇ」「へー」「へえ」などのリアクションを抽出・集計できます。

**精度向上のポイント**:
- 1文字ごとのスペース（`へ え`）に対応
- 改行を含むパターン（`へ\nえ`）に対応
- 全角スペースに対応（`へ　え`）
- 複数文字の繰り返し（`へええ`、`へえー`）に対応
- スペースと改行の混在（`へ \n え`）に対応

```bash
# 全エピソードを解析（デフォルトで前後2ブロックのコンテキスト付き）
python analyze_hee.py --all

# 詳細情報（タイムスタンプと文脈）を表示
python analyze_hee.py --all --details

# 特定のエピソードのみ解析
python analyze_hee.py "#32.機能性表示食品は誰のため？開発者目線で見るトクホとの違い"

# JSON形式で結果を保存
python analyze_hee.py --all --json hee_analysis_result.json

# === コンテキスト（前後の文脈）のカスタマイズ ===

# コンテキストなし（「へぇ」の箇所のみ）
python analyze_hee.py --all --details --context 0

# 前後を広く取る（前後5ブロック）
python analyze_hee.py "#32.機能性表示食品は誰のため？開発者目線で見るトクホとの違い" --details --context 5
```

**💡 重要**: デフォルトで前後2ブロック（約10-15秒の会話）のコンテキストが自動的に含まれます。`--context`オプションを指定しなくても、文脈が分かりやすい出力になります。

### 解析結果の例

```
================================================================================
「へぇ」リアクション解析結果
================================================================================

解析エピソード数: 146
「へぇ」を含むエピソード数: 91
「へぇ」総出現回数: 240

--------------------------------------------------------------------------------
エピソードごとの「へぇ」カウント
--------------------------------------------------------------------------------
[ 4回] #01.熱中症対策の甘いジュース、それ本当に大丈夫？〜砂糖の世界①
  └ 00:10:19,400: とか甘くて飲めなくなったりもするし、へえっていうその嗜好性の部分も...
  ...
[11回] 魚だけじゃない！体に良い油もテクノロジーで解決！？ #100 〜脂肪酸の科学⑤
  └ 00:02:15,200: へえ、そういう効果があるんだ...
  ...
```

### JSON出力形式

`--json`オプションで出力されるJSON形式の構造:

```json
[
  {
    "episode_name": "#32.機能性表示食品は誰のため？開発者目線で見るトクホとの違い",
    "count": 1,
    "instances": [
      {
        "timestamp": "00:01:58,960 --> 00:02:00,960",
        "text": "へ え、 効 果。 感 じ て る ん だ。",
        "cleaned_text": "へえ、効果。感じてるんだ。",
        "context": "みたい。な、本当に手ずっと動かしてる時とか食べてんだけど、まあなんか確かに圧迫感が減る気がする。へえ、効果。感じてるんだ。そうそう。実績わかんないよね。これはあれかもしれないけどね。プラシーボ効果かもしれないけどね。"
      }
    ]
  },
  {
    "episode_name": "#01.熱中症対策の甘いジュース、それ本当に大丈夫？〜砂糖の世界①",
    "count": 4,
    "instances": [
      {
        "timestamp": "00:10:19,400 --> 00:10:23,920",
        "text": "と か 甘 く て 飲 め な く な っ た り も す る し、 へ え っ て い う そ の 嗜 好 性 の 部 分 も",
        "cleaned_text": "とか甘くて飲めなくなったりもするし、へえっていうその嗜好性の部分も",
        "context": "前後のテキストを含む長い文章..."
      }
      // ... 残りの3件
    ]
  }
  // ... 他のエピソード
]
```

**フィールド説明**:
- `episode_name`: エピソード名
- `count`: そのエピソードでの「へぇ」の出現回数
- `instances`: 「へぇ」が出現した箇所の詳細リスト
  - `timestamp`: SRTファイルのタイムスタンプ（開始 --> 終了）
  - `text`: 元のテキスト（スペース入り）
  - `cleaned_text`: スペースを除去したテキスト（読みやすい形式）
  - `context`: 前後のコンテキストを含むテキスト（`--context`オプション使用時のみ、デフォルトは前後2ブロック）

### 活用方法

- **番組の盛り上がりポイントの特定**: 「へぇ」が多いエピソードは、驚きや発見が多い回
- **切り抜き候補の発見**: 「へぇ」の前後は視聴者の興味を引く内容
- **ゲストの反応分析**: ゲスト回での「へぇ」の多さで興味度を測定
- **コンテンツ改善**: 「へぇ」が少ないテーマは説明方法の見直しも検討
- **データ分析**: JSON形式で出力すれば、他のツールやスクリプトで更なる分析が可能

## 開発

```bash
# コードフォーマット
pipenv run format

# リンター実行
pipenv run lint

# 型チェック
pipenv run typecheck
```